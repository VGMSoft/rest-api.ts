[#chapter09-optimization]
= Optimisations

Bienvenue dans le dernier chapitre du livre. Le chemin a été long mais vous n’êtes qu’à un pas de la fin. Dans le chapitre précédent, nous avons terminé la modélisation du modèle de commandes. Nous pourrions dire que le projet est maintenant terminé mais je veux couvrir quelques détails importants sur l’optimisation. Les sujets que je vais aborder ici seront:

* la pagination
* la mise en cache
* l'optimisation des requêtes SQL
* l'activation de CORS

J’essaierai d’aller aussi loin que possible en essayant de couvrir certains scénarios courants. J’espère que ces scenarii vous seront utiles pour certains de vos projets.

Créons une nouvelle branche pour ce chapitre:

[source,bash]
----
$ git checkout -b chapter09
----

== Pagination

Une stratégie très commune pour optimiser la récupération d’enregistrements dans une base de données est de charger seulement une quantité limitée en les paginant. Nous allons le faire très facilement.

La seule partie délicate ici est de savoir comment gérer la sortie JSON pour donner assez d’informations au client sur la façon dont le tableau est paginé. Dans la section précédente, j’ai partagé quelques ressources sur les pratiques que j’allais suivre ici. L’une d’entre elles était http://jsonapi.org/[JSON:API].

La norme JSON:API impose un format stricte mais claire. Cela nous permet de ne pas se soucier de comment doit être implémentée. Une sous-section appelée https://jsonapi.org/format/#document-top-level[Top Level] de la documentation officielle de JSON:API mentionnent quelque chose sur la pagination:

> "meta": méta-information sur une ressource, telle que la pagination.

Ce n’est pas très descriptif mais au moins nous avons un indice sur ce qu’il faut regarder ensuite au sujet de l’implémentation de la pagination. Ne vous inquiétez pas, c’est exactement ce que nous allons faire ici.

Commençons par la liste des produits.

=== Les produits

// TODO

Nous devons fournir les informations de pagination sur la balise meta dans le formulaire suivant:

[source,json]
----
{
  "data": [
    ...
  ],
  "links": {
    "first": "/api/v1/products?page=1",
    "last": "/api/v1/products?page=30",
    "prev": "/api/v1/products",
    "next": "/api/v1/products?page=2"
  }
}
----

Maintenant que nous avons la structure finale de la balise meta, il ne nous reste plus qu’à la sortir sur la réponse JSON. Ajoutons d’abord quelques tests:

[source,ts]
.test/controllers/api/v1/products_controller_test.rb
----
// src/controllers/products.controller.spec.ts
// ...
describe('ProductsController', () => {
  // ...
  describe('index', () => {
    // ...
    it('should paginate results', async () => {
      for (let i = 0; i < 25; i++) {
        await productRepository.save(generateProduct({published: true}));
      }

      await agent
        .get('/products')
        .expect(200)
        .then(response => {
          assert.strictEqual(response.body.data.length, 20);
          assert.ok(response.body.links);
        });
    });
    // ...
  });
  // ...
});
----

Nous testons donc deux choses:

1. nous créons 25 produits nous devons donc en retrouver uniquement 20 lors de la réponse API car les résultats doivent se limiter à une seule page
2. nous devons retrouver les attributs `links` que nous avons vu précédemment

Notre but est donc de faire passer ces tests. Nous n'allons pas définir le comportement dans le contrôleur nous savons d'avance que nous vulons le même comportement pour tous les contrôleurs. Nous allons donc définir une `function` utilitaire qui va prendre en paramètre:

- la requête HTTP, qui nous permettra de retrouver facilement la paramètre `page` et aussi de construire les `links` en fonction de l'URL actuelle de la requête
- la requête SQL, qui sera utile pour savoir combien il y a de résultats en base de donnée et aussi appliquer les filtres `OFFSET` et `LIMIT` pour ne récupérer qu'une partie des résultats
- le serializer pour sérializer les données selon le schéma JSON:API

Allez c'est parti!

.Création de la méthode `paginate`
[source,ts]
----
// src/services/paginate.service.ts
import {Request} from 'express';
import {Serializer} from 'jsonapi-serializer';
import {SelectQueryBuilder} from 'typeorm';

const PER_PAGE = 20;

export async function getPaginatedJSONResponse<T>(
  queryBuilder: SelectQueryBuilder<T>,
  serializer: Serializer,
  {query, baseUrl}: Request,
) {
  const page = Number(query.page ?? 1);

  const count = await queryBuilder.getCount();
  const totalPage = Math.floor(count / PER_PAGE);
  const prevPage = page === 1 ? 1 : page - 1;
  const nextPage = page === totalPage ? page : page + 1;
  const offset = page > 1 ? (page - 1) * PER_PAGE : 0;

  const data = await queryBuilder
    .clone()
    .offset(offset)
    .limit(PER_PAGE)
    .getMany();

  const getUrlForPage = page =>
    `${baseUrl}?${new URLSearchParams({...query, page})}`;

  const response = serializer.serialize(data);
  response.links = {
    first: getUrlForPage(1),
    last: getUrlForPage(totalPage),
    prev: getUrlForPage(prevPage),
    next: getUrlForPage(nextPage),
  };

  return response;
}
----

L'implémentation est un peu longue mais nous allons la revoir ensemble:

1. `queryBuilder.getCount()` nous permet d'executer la requête passée en paramètre mais uniquement pour connaître le nombre de résultat
2. nous utilisons cette valeur pour calculer le nombre de pages et déduire le numéro de la page précédente et suivante
3. nous exécutons la requête SQL du `queryBuilder` en ajoutant un `offset` et une `limit`
4. nous générons les URL que nous ajoutons au résultat sérializé précédemmen

Vous êtes toujours là? L'implémentation dans le contrôleur est beaucoup plus facile:

[source,ts]
----
// src/controllers/home.controller.ts
// ...
import {paginate} from '../services/paginate.service';

@controller('/products')
export class ProductController {
  // ...
  @httpGet('/')
  public async index(/* ... */) {
    // ...
    return paginate(repository.search(req.query), productsSerializer, req);
  }
  // ...
}
----

Et voilà. Lançons les tests pour être sûr:

[source,sh]
---
$ npm test
...
  ProductsController
    index
      ✓ should paginate results (94ms)
...
---


Commitons tout cela et passons à la suite

[source,sh]
----
$ git add . && git commit -m "Paginate products"
----

Maintenant que nous avons fait une superbe optimisation pour la route de la liste des produits, c’est au client de parcourir les pages.

_Commitons_ ces changements et continuons avec la liste des commandes.

[source,bash]
----
$ git add .
$ git commit -m "Adds pagination for products index action to optimize response"
----

=== Liste des commandes

Maintenant, il est temps de faire exactement la même chose pour la route de la liste des commandes. Cela devrait être très facile à mettre en œuvre. Mais d’abord, ajoutons quelques tests:

[source,ts]
----
// src/controllers/orders.controller.spec.ts
// ...
describe('OrderController', () => {
  // ...
  describe('index', () => {
    // ...
    it('should paginate results', async () => {
      for (let i = 0; i < 20; i++) {
        await orderRepository.save(generateOrder({user}));
      }

      await agent
        .get('/orders')
        .set('Authorization', jwt)
        .expect(200)
        .then(response => {
          assert.strictEqual(response.body.data.length, 20);
          assert.ok(response.body.links);
        });
    });
  });
  // ...
});
----

Et, comme vous vous en doutez peut-être déjà, nos tests ne passent plus:

[source,bash]
----
$ npm test
...
  1 failing

  1) OrderController
       index
         should paginate results:

      AssertionError [ERR_ASSERTION]: Expected values to be strictly equal:

21 !== 20

      + expected - actual

      -21
      +20
----

Faire passe ce test est là encore assez facile.

.Implémentation de la pagination pour les commandes
[source,ts]
----
// src/controllers/orders.controller.ts
// ...
@controller('/orders', TYPES.FetchLoggedUserMiddleware)
export class OrdersController {
  // ...
  @httpGet('/')
  public async index(req: Request & {user: User}) {
    const {manager} = await this.databaseService.getConnection();

    return paginate(
      manager
        .createQueryBuilder(Order, 'o')
        .where('o.user = :user', {user: req.user.id}),
      ordersSerializer,
      req,
    );
  }
  // ...
}
----

La seule différence par rapport à l'implémentation du controleur des produit est que ici nous avons eu besoin de transformer `repository.find` en `queryBuilder`.

Les tests devraient maintenant passer:

[source,bash]
----
$ npm test
...
  46 passing (781ms)
----

Faisons un _commit_ avant d’avancer

[source,bash]
----
$ git commit -am "Adds pagination for orders index action"
----

== Mise en cache

Nous pouvons facilement mettre e place une mise en cache simple pour certains de nos _endpoint_. L'implémentation sera vraiment très facile grâce à TypeORM.

Si nous effectuons une demande à la liste des produits, nous remarquerons que le temps de réponse prend environ 20 millisecondes en utilisant cURL

[source,bash]
----
$ curl -w 'Total: %{time_total}\n' -o /dev/null -s http://localhost:3000/products
Total: 0,137088
----

NOTE: L’option `-w` nous permet de récupérer le temps de la requête, `-o` redirige la réponse vers un fichier et `-s` masque l’affichage de cURL

En ajoutant seulement une ligne à la classe `ProductSerializer`, nous verrons une nette amélioration du temps de réponse!

[source,ruby]
.app/serializers/order_serializer.rb
----
class OrderSerializer
  # ...
  cache_options enabled: true, cache_length: 12.hours
end
----

[source,ruby]
.app/serializers/product_serializer.rb
----
class ProductSerializer
  # ...
  cache_options enabled: true, cache_length: 12.hours
end
----

[source,ruby]
.app/serializers/user_serializer.rb
----
class UserSerializer
  # ...
  cache_options enabled: true, cache_length: 12.hours
end
----

Et c’est tout! Vérifions l’amélioration:

[source,bash]
----
$ curl -w 'Total: %{time_total}\n' -o /dev/null -s http://localhost:3000/products
Total: 0,054786
$ curl -w 'Total: %{time_total}\n' -o /dev/null -s http://localhost:3000/products/
Total: 0,032341
----

Nous sommes donc passés de 137 ms à 40 ms. L’amélioration est donc énorme! _Committons_ une dernière fois nos changements.

[source,ruby]
----
$ git commit -am "Adds caching for the serializers"
----


== Activation des CORS

Dans cette dernière section, je vais vous parler d'un dernier problème que vous allez sûrement rencontrer si vous êtes amenés à travailler avec votre API.

Lors de la première requête d'un site externe (via une requête AJAX par exemple), vous aller rencontrer une erreur de ce genre:

> Failed to load https://example.com/: No ‘Access-Control-Allow-Origin’ header is present on the requested resource. Origin ‘https://anfo.pl' is therefore not allowed access. If an opaque response serves your needs, set the request’s mode to ‘no-cors’ to fetch the resource with CORS disabled.

"Mais qu'est ce que signifie _Access-Control-Allow-Origin_??". Le comportement que vous observez est l'effet de l'implémentation CORS des navigateurs. Avant la standardisation de CORS, il n'y avait aucun moyen d'appeler un terminal API sous un autre domaine pour des raisons de sécurité. Ceci a été (et est encore dans une certaine mesure) bloqué par la politique de la même origine.

CORS est un mécanisme qui a pour but de permettre les requêtes faites en votre nom et en même temps de bloquer certaines requêtes faites par des scripts malhonnêtes et est déclenché lorsque vous faites une requête HTTP à:

- un domaine différent
- un sous-domaine différent
- un port différent
- un protocole différent

Nous devons manuellement activer cette fonctionnalité afin que n'importe quel client puisse effectuer des requêtes sur notre API.



Rails nous permet de faire ça très facilement. Jetez un coup d'œil au fichier `cors.rb` situé dans le dossier `initializers`.

[source,ruby]
.config/initializers/cors.rb
----
# ...

# Rails.application.config.middleware.insert_before 0, Rack::Cors do
#   allow do
#     origins 'example.com'
#
#     resource '*',
#       headers: :any,
#       methods: [:get, :post, :put, :patch, :delete, :options, :head]
#   end
# end
----

Vous voyez. Il suffit de dé-commenter le code et de le modifier un peut pour limiter l'accès à certaines actions ou bien certains verbes HTTP. Dans notre cas, cette configuration nous convient très bien pour le moment.

[source,ruby]
.config/initializers/cors.rb
----
# ...

Rails.application.config.middleware.insert_before 0, Rack::Cors do
  allow do
    origins 'example.com'
    resource '*',
      headers: :any,
      methods: [:get, :post, :put, :patch, :delete, :options, :head]
  end
end
----

Nous devons aussi installer la gemme `rack-cors` qui est commentée dans le `Gemfile`:

[source,bash]
----
$ bundle add rack-cors
----

Et voilà! Il est maintenant temps de faire notre dernier commit et de merger nos modifications sur la branche master.


[source,bash]
----
$ git commit -am "Activate CORS"
$ git checkout master
$ git merge chapter09
----

== Conclusion

Si vous arrivez à ce point, cela signifie que vous en avez fini avec le livre. Bon travail! Vous venez de devenir un grand développeur API Rails, c’est sûr.

Nous avons donc construit ensemble une API solide et complète. Celle-ci possède toutes les qualité pour détrôner https://www.amazon.com/[Amazon], soyez en sûr. Merci d’avoir traversé cette grande aventure avec moi, j’espère que vous avez apprécié le voyage autant que moi.

Je tiens à vous rappeler que tout le code source de ce livre est disponible au format https://asciidoctor.org[Asciidoctor] sur https://github.com/madeindjs/api_on_rails[GitHub]. Ainsi n’hésitez pas à https://github.com/madeindjs/api_on_rails/fork[forker] le projet si vous voulez l’améliorer ou corriger une faute qui m’aurait échappée.

Si vous avez aimé ce livre, n'hésitez pas à me le faire savoir par mail mailto:contact@rousseau-alexandre.fr[contact@rousseau-alexandre.fr]. Je suis ouvert à toutes critiques, bonne ou mauvaise, autour d'un bonne bière :) .
